{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower_claas_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24apanda/CNN/blob/master/Flower_claas_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDbtHnVLWte_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bCq6wLV-dU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "f6bf8648-853c-4062-d766-44d6d25c74a2"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows = 224\n",
        "img_cols = 224 \n",
        "\n",
        "#Loads the VGG16 model \n",
        "vgg16 = VGG16(weights = 'imagenet', \n",
        "                 include_top = False, \n",
        "                 input_shape = (img_rows, img_cols, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLM96lbkWnbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "fb74d466-5b26-44f6-eec7-4422d1e830c3"
      },
      "source": [
        "# Let's print our layers \n",
        "for (i,layer) in enumerate(vgg16.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D True\n",
            "2 Conv2D True\n",
            "3 MaxPooling2D True\n",
            "4 Conv2D True\n",
            "5 Conv2D True\n",
            "6 MaxPooling2D True\n",
            "7 Conv2D True\n",
            "8 Conv2D True\n",
            "9 Conv2D True\n",
            "10 MaxPooling2D True\n",
            "11 Conv2D True\n",
            "12 Conv2D True\n",
            "13 Conv2D True\n",
            "14 MaxPooling2D True\n",
            "15 Conv2D True\n",
            "16 Conv2D True\n",
            "17 Conv2D True\n",
            "18 MaxPooling2D True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HNdvfHeXaie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "86b74a0d-9499-4fc4-cfec-a60ae5a53cc1"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows = 224\n",
        "img_cols = 224 \n",
        "\n",
        "# Re-loads the VGG16 model without the top or FC layers\n",
        "vgg16 = VGG16(weights = 'imagenet', \n",
        "                 include_top = False, \n",
        "                 input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "# Here we freeze the last 4 layers \n",
        "# Layers are set to trainable as True by default\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Let's print our layers \n",
        "for (i,layer) in enumerate(vgg16.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FitnMyo8Xr6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addTopModel(bottom_model, num_classes, D=256):\n",
        "    \"\"\"creates the top or head of the model that will be \n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "    top_model = bottom_model.output\n",
        "    top_model = Flatten(name = \"flatten\")(top_model)\n",
        "    top_model = Dense(D, activation = \"relu\")(top_model)\n",
        "    top_model = Dropout(0.3)(top_model)\n",
        "    top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
        "    return top_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfZLrGVhX-gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "224041cc-414a-4a31-a76a-ab8853652674"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "num_classes = 17\n",
        "\n",
        "FC_Head = addTopModel(vgg16, num_classes)\n",
        "\n",
        "model = Model(inputs=vgg16.input, outputs=FC_Head)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                4369      \n",
            "=================================================================\n",
            "Total params: 21,141,841\n",
            "Trainable params: 6,427,153\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-oz2DJYDLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/Colab Notebooks/17_flowers/train'\n",
        "validation_data_dir = '/content/drive/My Drive/Colab Notebooks/17_flowers/validation'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1dcoMEdYY-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batchsize = 32\n",
        "val_batchsize = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZpnBTojYkg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eda50b09-081a-42a0-c92e-1163e582e8f4"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1190 images belonging to 17 classes.\n",
            "Found 170 images belonging to 17 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMzGyGzEYoyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "260e0784-5014-4cf1-dc8a-85b9b422a09c"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "                   \n",
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/model/flowers_vgg.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]\n",
        "\n",
        "# Note we use a very small learning rate \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(lr = 0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "nb_train_samples = 1190\n",
        "nb_validation_samples = 170\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)\n",
        "\n",
        "model.save(\"/content/drive/My Drive/Colab Notebooks/model/flowers_vgg.h5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "74/74 [==============================] - 35s 470ms/step - loss: 1.0916 - acc: 0.6806 - val_loss: 0.6102 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.61022, saving model to /content/drive/My Drive/Colab Notebooks/model/flowers_vgg.h5\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 34s 459ms/step - loss: 0.8406 - acc: 0.7311 - val_loss: 0.5172 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.61022 to 0.51716, saving model to /content/drive/My Drive/Colab Notebooks/model/flowers_vgg.h5\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 34s 454ms/step - loss: 0.7883 - acc: 0.7507 - val_loss: 0.7175 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.51716\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 34s 456ms/step - loss: 0.6904 - acc: 0.7775 - val_loss: 0.5874 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.51716\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 34s 460ms/step - loss: 0.6196 - acc: 0.7872 - val_loss: 0.4407 - val_acc: 0.8896\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.51716 to 0.44068, saving model to /content/drive/My Drive/Colab Notebooks/model/flowers_vgg.h5\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 34s 464ms/step - loss: 0.6194 - acc: 0.7939 - val_loss: 0.8462 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.44068\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 34s 464ms/step - loss: 0.5470 - acc: 0.8260 - val_loss: 0.6363 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.44068\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 33s 448ms/step - loss: 0.4994 - acc: 0.8373 - val_loss: 0.7460 - val_acc: 0.8377\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.44068\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_b9LtSLY-pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}